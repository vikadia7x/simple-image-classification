{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the following packages using pip:\n",
    "    1) Tensorflow\n",
    "    2) Keras\n"
        
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/anaconda3/envs/catvsdog/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import MaxPooling2D\n",
    "\n",
    "from IPython.display import display\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a CNN object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Convolution Layer and Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Conv2D(32,(3,3), input_shape = (64,64,3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Convolution Layer and Pooling Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Conv2D(32,(3,3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattening Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the final fully connected network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to compile the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that the network is built, our task is to fit the images into the network. We need to first rescale and generate new(flipped) images for our input and then fit the training data into our network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescaling and loading train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_scale = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "test_data_scale = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_set = train_data_scale.flow_from_directory('Path/train_set',target_size = (64,64), batch_size = 32, class_mode = 'binary')\n",
    "test_set = test_data_scale.flow_from_directory('Path/test_set',target_size = (64,64), batch_size = 32, class_mode = 'binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now its time to fit the data into our classifier object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "8000/8000 [==============================] - 1865s 233ms/step - loss: 0.3320 - acc: 0.8453 - val_loss: 0.7011 - val_acc: 0.7990\n",
      "Epoch 2/25\n",
      "8000/8000 [==============================] - 2129s 266ms/step - loss: 0.0816 - acc: 0.9699 - val_loss: 0.9271 - val_acc: 0.8105\n",
      "Epoch 3/25\n",
      "8000/8000 [==============================] - 1941s 243ms/step - loss: 0.0444 - acc: 0.9843 - val_loss: 1.0201 - val_acc: 0.8100\n",
      "Epoch 4/25\n",
      "8000/8000 [==============================] - 1718s 215ms/step - loss: 0.0331 - acc: 0.9887 - val_loss: 1.2585 - val_acc: 0.8025\n",
      "Epoch 5/25\n",
      "8000/8000 [==============================] - 1720s 215ms/step - loss: 0.0270 - acc: 0.9910 - val_loss: 1.2872 - val_acc: 0.7945\n",
      "Epoch 6/25\n",
      "8000/8000 [==============================] - 1718s 215ms/step - loss: 0.0233 - acc: 0.9924 - val_loss: 1.3079 - val_acc: 0.8035\n",
      "Epoch 7/25\n",
      "8000/8000 [==============================] - 1720s 215ms/step - loss: 0.0209 - acc: 0.9934 - val_loss: 1.3827 - val_acc: 0.7925\n",
      "Epoch 8/25\n",
      "8000/8000 [==============================] - 1717s 215ms/step - loss: 0.0169 - acc: 0.9945 - val_loss: 1.5598 - val_acc: 0.7930\n",
      "Epoch 9/25\n",
      "8000/8000 [==============================] - 1719s 215ms/step - loss: 0.0170 - acc: 0.9945 - val_loss: 1.4632 - val_acc: 0.8165\n",
      "Epoch 10/25\n",
      "8000/8000 [==============================] - 1717s 215ms/step - loss: 0.0151 - acc: 0.9953 - val_loss: 1.5476 - val_acc: 0.8055\n",
      "Epoch 11/25\n",
      "8000/8000 [==============================] - 1715s 214ms/step - loss: 0.0133 - acc: 0.9958 - val_loss: 1.4604 - val_acc: 0.8075\n",
      "Epoch 12/25\n",
      "8000/8000 [==============================] - 1716s 215ms/step - loss: 0.0126 - acc: 0.9961 - val_loss: 1.5738 - val_acc: 0.8050\n",
      "Epoch 13/25\n",
      "8000/8000 [==============================] - 1718s 215ms/step - loss: 0.0124 - acc: 0.9964 - val_loss: 1.5590 - val_acc: 0.8190\n",
      "Epoch 14/25\n",
      "8000/8000 [==============================] - 1717s 215ms/step - loss: 0.0118 - acc: 0.9965 - val_loss: 1.7984 - val_acc: 0.7935\n",
      "Epoch 15/25\n",
      "8000/8000 [==============================] - 1719s 215ms/step - loss: 0.0100 - acc: 0.9969 - val_loss: 1.5662 - val_acc: 0.8100\n",
      "Epoch 16/25\n",
      "8000/8000 [==============================] - 1719s 215ms/step - loss: 0.0107 - acc: 0.9969 - val_loss: 1.6375 - val_acc: 0.8075\n",
      "Epoch 17/25\n",
      "8000/8000 [==============================] - 1721s 215ms/step - loss: 0.0099 - acc: 0.9970 - val_loss: 1.8262 - val_acc: 0.7825\n",
      "Epoch 18/25\n",
      "8000/8000 [==============================] - 4092s 511ms/step - loss: 0.0098 - acc: 0.9971 - val_loss: 1.7600 - val_acc: 0.8025\n",
      "Epoch 19/25\n",
      "8000/8000 [==============================] - 6603s 825ms/step - loss: 0.0087 - acc: 0.9973 - val_loss: 1.6329 - val_acc: 0.8030\n",
      "Epoch 20/25\n",
      "8000/8000 [==============================] - 1861s 233ms/step - loss: 0.0094 - acc: 0.9973 - val_loss: 1.7792 - val_acc: 0.7995\n",
      "Epoch 21/25\n",
      "8000/8000 [==============================] - 13691s 2s/step - loss: 0.0087 - acc: 0.9976 - val_loss: 1.8960 - val_acc: 0.7995\n",
      "Epoch 22/25\n",
      "8000/8000 [==============================] - 23265s 3s/step - loss: 0.0084 - acc: 0.9976 - val_loss: 1.8950 - val_acc: 0.7945\n",
      "Epoch 23/25\n",
      "8000/8000 [==============================] - 2066s 258ms/step - loss: 0.0083 - acc: 0.9977 - val_loss: 1.8259 - val_acc: 0.8045\n",
      "Epoch 24/25\n",
      "8000/8000 [==============================] - 2121s 265ms/step - loss: 0.0075 - acc: 0.9978 - val_loss: 1.7912 - val_acc: 0.8045\n",
      "Epoch 25/25\n",
      "8000/8000 [==============================] - 2378s 297ms/step - loss: 0.0073 - acc: 0.9979 - val_loss: 1.7958 - val_acc: 0.8125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10e4f3630>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(train_set, steps_per_epoch = 8000, epochs = 25, validation_data = test_set, validation_steps = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Its time to make new predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the test image and convert it into a pixel array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_new_image = image.load_img('Path', target_size = (64,64))\n",
    "test_new_image = image.img_to_array(test_new_image)\n",
    "test_new_image = np.expand_dims(test_new_image, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Classify and print the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = classifier.predict(test_new_image)\n",
    "train_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "    \n",
    "print(\"The result is \",prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
